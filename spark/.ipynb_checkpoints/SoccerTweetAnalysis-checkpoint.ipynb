{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soccer Tweet Analysis\n",
    "\n",
    "Código utilizado para responder as questões durante uma das provas na especialização em Big Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and create a new SQLContext \n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the country CSV file into an RDD.\n",
    "country_lines = sc.textFile('file:///home/cloudera/Downloads/big-data-3/final-project/country-list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each line into a pair of words\n",
    "words = country_lines.flatMap(lambda line : line.split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each pair of words into a tuple\n",
    "tuples = country_lines.map(lambda line : (line.split(',')[0], line.split(',')[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='Afghanistan', code=' AFG'),\n",
       " Row(country='Albania', code=' ALB'),\n",
       " Row(country='Algeria', code=' ALG')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame, look at schema and contents\n",
    "countryDF = sqlContext.createDataFrame(tuples, [\"country\", \"code\"])\n",
    "countryDF.printSchema()\n",
    "countryDF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweets CSV file into RDD of lines\n",
    "tweet_lines = sc.textFile('file:///home/cloudera/Desktop/tweet_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data: some tweets are empty. Remove the empty tweets using filter() \n",
    "tweet_clean=tweet_lines.filter(lambda x: len(x)>0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform WordCount on the cleaned tweet texts. (note: this is several lines.)\n",
    "t_words = tweet_clean.flatMap(lambda line : line.split(\" \"))\n",
    "t_tuples = t_words.map(lambda word : (word,1))\n",
    "counts = t_tuples.reduceByKey(lambda a, b: (a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(word='', count=3292),\n",
       " Row(word='https://t.co/fQftAwGAad', count=1),\n",
       " Row(word='mobile', count=1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame of tweet word counts\n",
    "countDF = sqlContext.createDataFrame(counts, [\"word\", \"count\"])\n",
    "countDF.printSchema()\n",
    "countDF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='Thailand', code=' THA', word='Thailand', count=1),\n",
       " Row(country='Iceland', code=' ISL', word='Iceland', count=2),\n",
       " Row(country='Mexico', code=' MEX', word='Mexico', count=1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the country and tweet DataFrames (on the appropriate column)\n",
    "merge = countryDF.join(countDF, countryDF.country == countDF.word)\n",
    "merge.printSchema()\n",
    "merge.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1: number of distinct countries mentioned\n",
    "merge.filter(merge[\"count\"] > 0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|       397|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 2: number of countries mentioned in tweets.\n",
    "from pyspark.sql.functions import sum\n",
    "merge.select(sum('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----------+-----+\n",
      "|    country|code|       word|count|\n",
      "+-----------+----+-----------+-----+\n",
      "|     Norway| NOR|     Norway|   52|\n",
      "|    Nigeria| NGA|    Nigeria|   49|\n",
      "|     France| FRA|     France|   42|\n",
      "|   Slovakia| SVK|   Slovakia|   30|\n",
      "|    England| ENG|    England|   25|\n",
      "|    Germany| GER|    Germany|   20|\n",
      "|      Wales| WAL|      Wales|   19|\n",
      "|     Russia| RUS|     Russia|   15|\n",
      "|     Brazil| BRA|     Brazil|   13|\n",
      "|Netherlands| NED|Netherlands|   13|\n",
      "|     Canada| CAN|     Canada|   11|\n",
      "|Switzerland| SUI|Switzerland|   10|\n",
      "|       Chad| CHA|       Chad|    9|\n",
      "|     Guinea| GUI|     Guinea|    8|\n",
      "|      Spain| ESP|      Spain|    8|\n",
      "|   Portugal| POR|   Portugal|    8|\n",
      "|       Iraq| IRQ|       Iraq|    6|\n",
      "|     Jordan| JOR|     Jordan|    6|\n",
      "|      Japan| JPN|      Japan|    5|\n",
      "|    Austria| AUT|    Austria|    5|\n",
      "+-----------+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 1: top three countries and their counts.\n",
    "from pyspark.sql.functions import desc\n",
    "merge.sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(count)|\n",
      "+-----------------+\n",
      "|9.022727272727273|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 2: counts for Wales, Iceland, and Japan.\n",
    "from pyspark.sql.functions import *\n",
    "merge.select(mean('count')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
